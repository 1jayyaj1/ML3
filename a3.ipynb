{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "a3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.0 64-bit",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0-final"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-2lfpAKQLcN",
        "outputId": "0b549208-e622-42c4-ed46-b9f1d398d880"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from matplotlib import pyplot as plt\n",
        "import cv2\n",
        "from skimage.transform import resize\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import h5py\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab.patches import cv2_imshow\n",
        "from matplotlib import pyplot as plt\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "path = '/content/drive/My Drive/Colab_Notebooks/'\n",
        "path2 = '/content/drive/My Drive/Colab Notebooks/'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ddve4yQZZOhH"
      },
      "source": [
        "# Transform used to process training set and testing set data\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5), (0.5))])\n",
        "\n",
        "# Create training set\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "# Create training loader\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "# Create testing set\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "\n",
        "# Create testing loaders\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=32,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "# All possible digit classes\n",
        "classes = ('0', '1', '2', '3', '4', '5', '6', '7', '8', '9')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4udYkUtFy3z"
      },
      "source": [
        "# Net class with the specified layers\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv3 = nn.Conv2d(64, 64, 3)\n",
        "        self.conv4 = nn.Conv2d(64, 64, 3)\n",
        "        self.fc1 = nn.Linear(64 * 64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = x.view(-1, 64 * 64)\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate net class\n",
        "net = Net()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQMPcr-KF2WK"
      },
      "source": [
        "# Set loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Instantiate SGD optimizer\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1YCz11RF4s4",
        "outputId": "d176722c-e297-4342-9d91-b959c58b4faf"
      },
      "source": [
        "# Train over 3 epochs\n",
        "for epoch in range(3):  # loop over the dataset multiple times\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 500 == 499:    # print every 500 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 500))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,   500] loss: 2.291\n",
            "[1,  1000] loss: 2.240\n",
            "[1,  1500] loss: 1.735\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKrmAD74F8KV"
      },
      "source": [
        "# Save our net as mnist_net.pt.pth\n",
        "PATH = './mnist_net.pth'\n",
        "torch.save(net.state_dict(), PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3TWARjy4ZnL"
      },
      "source": [
        "def split_image(image):\n",
        "  preprocessed_digits = []\n",
        "  image = np.squeeze(image)\n",
        "  grey = image.copy()\n",
        "  thresh = grey.copy()\n",
        "  contours, _ = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "  for c in contours:\n",
        "      x,y,w,h = cv2.boundingRect(c)\n",
        "\n",
        "      cv2.rectangle(image, (x,y), (x+w, y+h), color=(0, 255, 0), thickness=2)\n",
        "\n",
        "      digit = thresh[y:y+h, x:x+w]\n",
        "      \n",
        "      resized_digit = cv2.resize(digit, (18,18))\n",
        "      \n",
        "      padded_digit = np.pad(resized_digit, ((7,7),(7,7)), \"constant\", constant_values=0)\n",
        "      \n",
        "      preprocessed_digits.append(padded_digit)\n",
        "\n",
        "  digits = torch.from_numpy(np.array(preprocessed_digits, dtype='uint8'))\n",
        "  return digits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWtOT8KNfHth"
      },
      "source": [
        "def sum_left_col(window):\n",
        "  left_col = window[:,:1,:]\n",
        "  sum_left_col = left_col.sum(axis=1)\n",
        "  return np.max(sum_left_col) == 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrloMfKEMx9t"
      },
      "source": [
        "def kernel_blur(image,w,h):\n",
        "  kernel = np.ones((3,3),np.float32)/9\n",
        "  dst = cv2.filter2D(image,-1,kernel)\n",
        "  dst = np.reshape(dst, (w,h,1))\n",
        "  return dst"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dCHuUiATlIG"
      },
      "source": [
        "def split_image2(image):\n",
        "  digits2 = []\n",
        "  img = image.copy()\n",
        "\n",
        "  img = kernel_blur(img,64,64)\n",
        "\n",
        "  idx = img[:,:,0] < 40\n",
        "  img[idx,0] = 0\n",
        "\n",
        "  idx2 = img[:,:,0] > 90\n",
        "  img[idx2,0] = 255\n",
        "  \n",
        "  '''\n",
        "  test = np.squeeze(img)\n",
        "  plt.imshow(test, cmap='gray')\n",
        "  plt.show()\n",
        "  '''\n",
        "  prev = None\n",
        "  # Assuming square image\n",
        "  for x in range(len(img)):\n",
        "    window = img[24:40,x:x+10,:]\n",
        "    is_left_black = sum_left_col(window)\n",
        "    \n",
        "    if prev and not is_left_black:\n",
        "      if x + 10 > len(img) - 1:\n",
        "        digits2.append(image[24:40,x:,:])\n",
        "        break\n",
        "      else:\n",
        "        digits2.append(image[24:40,x:x+10,:])\n",
        "\n",
        "    prev = is_left_black\n",
        "  \n",
        "  return digits2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7aDlOGYQ2oZ",
        "outputId": "88f9a5a2-66fc-43b3-9e72-9aa4365b92a1"
      },
      "source": [
        "hf = h5py.File(path + 'MNIST_synthetic.h5', 'r')\n",
        "print(hf.keys())\n",
        "\n",
        "X_train = hf['train_dataset']\n",
        "print(X_train.shape)\n",
        "\n",
        "y_train = np.array(hf['train_labels'])\n",
        "print(y_train.shape)\n",
        "\n",
        "X_test = hf['test_dataset']\n",
        "print(X_test.shape)\n",
        "\n",
        "y_test = np.array([np.array([9,10,10,10,10]),np.array([0,1,7,3,10]),np.array([1,4,0,8,3]),np.array([0,10,10,10,10]),np.array([4,6,7,8,10]),np.array([0,10,10,10,10]),np.array([6,9,2,10,10]),np.array([3,7,10,10,10]),np.array([4,8,2,6,7]),np.array([9,6,6,0,10])])\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<KeysViewHDF5 ['test_dataset', 'train_dataset', 'train_labels']>\n",
            "(56000, 64, 64, 1)\n",
            "(56000, 5)\n",
            "(14000, 64, 64, 1)\n",
            "(10, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEpjoGBQpwSi",
        "outputId": "7cb70fbf-e903-4465-d71e-eb3bf53ea294"
      },
      "source": [
        "# Instantiate net class\n",
        "net = Net()\n",
        "net.load_state_dict(torch.load(PATH))\n",
        "\n",
        "test_im3 = []\n",
        "probs3 = []\n",
        "for i in range(len(X_train)):\n",
        "  temp3 = X_train[i].copy()\n",
        "  digits3 = split_image2(temp3)\n",
        "\n",
        "  if 5-(list(y_train[i]).count(10)) != len(digits3):\n",
        "    probs3.append(i)\n",
        "  for j3 in digits3:\n",
        "    test_im3.append(j3)\n",
        "      \n",
        "print('Total number of digits detected: ' + str(len(test_im3)))\n",
        "print('Total number of problematic images: ' + str(len(probs3)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of digits detected: 167893\n",
            "Total number of problematic images: 41\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyvxssy8rk4Q"
      },
      "source": [
        "# Displays the problematic images identified above in probs3\n",
        "for i in range(len(probs3)):\n",
        "  im3 = np.squeeze(X_train[probs3[i]])\n",
        "  plt.imshow(im3, cmap='gray')\n",
        "  plt.show()\n",
        "  digits3 = split_image2(X_train[probs3[i]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nR9M_CatdRx",
        "outputId": "26898f39-f1a1-43dc-fdd9-b39266ca7844"
      },
      "source": [
        "c = 0\n",
        "for y in y_train:\n",
        "  c += 5 - list(y).count(10)\n",
        "\n",
        "print('There are ' + str(c) + ' digits in the ' + str(len(y_train)) + ' training sample images')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 167886 digits in the 56000 training sample images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTy0mBgApExa"
      },
      "source": [
        "# Rayan's Additions here!\n",
        "class H5Dataset(torch.utils.data.Dataset):\n",
        "\n",
        "  def __init__(self, h5File):\n",
        "      super(H5Dataset, self).__init__()\n",
        "      hf = h5py.File(h5File , 'r')\n",
        "      self.train_label = np.array(hf['train_labels'])\n",
        "      self.train_label = self.train_label.flatten()\n",
        "      self.train_label = self.train_label[self.train_label != 10]\n",
        "      self.train_data = np.array(hf['train_dataset'])\n",
        "      test_im = []\n",
        "      for i in range(len(self.train_data)):\n",
        "        for j in split_image(self.train_data[i]):\n",
        "          test_im.append(j)\n",
        "      self.train_data = torch.stack(test_im) \n",
        "      self.train_data = torch.unsqueeze(self.train_data, 1)\n",
        "\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return (self.train_data[index, :,:, :], torch.from_numpy(self.train_label)[index])\n",
        "\n",
        "  def __len__(self):\n",
        "      return self.train_label.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNI5_QtIpKYN"
      },
      "source": [
        "train_dataset = H5Dataset(path2 + 'MNIST_synthetic.h5')\n",
        "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle = True, num_workers=2)\n",
        "\n",
        "\n",
        "dataiter = iter(trainloader)\n",
        "images,labels = dataiter.next()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhVnei1FpM9U"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        #print(images.shape)\n",
        "        #print(labels.shape)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        #print(predicted.shape)\n",
        "        if (len(predicted) != len(labels)):\n",
        "          predicted = predicted[0:16]\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the test images: %d %%' % (\n",
        "    100 * correct / total))\n",
        "\n",
        "# END OF RAYAN'S ADDITIONS!"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}